{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu124\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basically creating a tensor, but why are we calling it a scalar?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scalar\n",
    "scalar =torch.tensor(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# so it has 0 dimension , which makes sense\n",
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting back int form python data types \n",
    "scalar.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector=torch.tensor([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix=torch.tensor([[1,2,3],[4,5,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix[0,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensors=torch.tensor([[[1,2,3],[4,5,6]],[[1,2,3],[4,5,6]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [4, 5, 6]],\n",
       "\n",
       "        [[1, 2, 3],\n",
       "         [4, 5, 6]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 3])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensors[0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random tensor\n",
    "\n",
    "Random tensors are important because the way many neural networks learn is they have random tensor at the beginning and then those numbers are updated ,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a random tensor of size(4,5)\n",
    "random_tensor=torch.rand(4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9525, 0.5990, 0.5369, 0.0340, 0.7408],\n",
       "        [0.2241, 0.2574, 0.0703, 0.1525, 0.0930],\n",
       "        [0.8796, 0.7477, 0.2990, 0.0600, 0.1459],\n",
       "        [0.0154, 0.9468, 0.6462, 0.9703, 0.4566]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating a random image tensor\n",
    "random_tensor_image=torch.rand(224,224,3) #height , width and color channel\n",
    "random_tensor_image.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tensors with binary bits\n",
    "zero_tensor=torch.zeros(4,4)\n",
    "zero_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(zero_tensor,random_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It seems that the default data type for tensor is float32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating zeros tensor which has shape of exisiting tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 5])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_like=torch.zeros_like(random_tensor)\n",
    "zero_like.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 5])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### arange , start, stop, step (kind of like python built in range)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  3,  5,  7,  9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35,\n",
       "        37, 39, 41, 43, 45, 47, 49, 51, 53, 55, 57, 59, 61, 63, 65, 67, 69, 71,\n",
       "        73, 75, 77, 79, 81, 83, 85, 87, 89, 91, 93, 95, 97, 99])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_to_somewhere=torch.arange(1,100,2)\n",
    "one_to_somewhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0000,  1.5000,  2.0000,  2.5000,  3.0000,  3.5000,  4.0000,  4.5000,\n",
       "         5.0000,  5.5000,  6.0000,  6.5000,  7.0000,  7.5000,  8.0000,  8.5000,\n",
       "         9.0000,  9.5000, 10.0000, 10.5000, 11.0000, 11.5000, 12.0000, 12.5000,\n",
       "        13.0000, 13.5000, 14.0000, 14.5000, 15.0000, 15.5000, 16.0000, 16.5000,\n",
       "        17.0000, 17.5000, 18.0000, 18.5000, 19.0000, 19.5000, 20.0000, 20.5000,\n",
       "        21.0000, 21.5000, 22.0000, 22.5000, 23.0000, 23.5000, 24.0000, 24.5000,\n",
       "        25.0000, 25.5000, 26.0000, 26.5000, 27.0000, 27.5000, 28.0000, 28.5000,\n",
       "        29.0000, 29.5000, 30.0000, 30.5000, 31.0000, 31.5000, 32.0000, 32.5000,\n",
       "        33.0000, 33.5000, 34.0000, 34.5000, 35.0000, 35.5000, 36.0000, 36.5000,\n",
       "        37.0000, 37.5000, 38.0000, 38.5000, 39.0000, 39.5000, 40.0000, 40.5000,\n",
       "        41.0000, 41.5000, 42.0000, 42.5000, 43.0000, 43.5000, 44.0000, 44.5000,\n",
       "        45.0000, 45.5000, 46.0000, 46.5000, 47.0000, 47.5000, 48.0000, 48.5000,\n",
       "        49.0000, 49.5000, 50.0000, 50.5000, 51.0000, 51.5000, 52.0000, 52.5000,\n",
       "        53.0000, 53.5000, 54.0000, 54.5000, 55.0000, 55.5000, 56.0000, 56.5000,\n",
       "        57.0000, 57.5000, 58.0000, 58.5000, 59.0000, 59.5000, 60.0000, 60.5000,\n",
       "        61.0000, 61.5000, 62.0000, 62.5000, 63.0000, 63.5000, 64.0000, 64.5000,\n",
       "        65.0000, 65.5000, 66.0000, 66.5000, 67.0000, 67.5000, 68.0000, 68.5000,\n",
       "        69.0000, 69.5000, 70.0000, 70.5000, 71.0000, 71.5000, 72.0000, 72.5000,\n",
       "        73.0000, 73.5000, 74.0000, 74.5000, 75.0000, 75.5000, 76.0000, 76.5000,\n",
       "        77.0000, 77.5000, 78.0000, 78.5000, 79.0000, 79.5000, 80.0000, 80.5000,\n",
       "        81.0000, 81.5000, 82.0000, 82.5000, 83.0000, 83.5000, 84.0000, 84.5000,\n",
       "        85.0000, 85.5000, 86.0000, 86.5000, 87.0000, 87.5000, 88.0000, 88.5000,\n",
       "        89.0000, 89.5000, 90.0000, 90.5000, 91.0000, 91.5000, 92.0000, 92.5000,\n",
       "        93.0000, 93.5000, 94.0000, 94.5000, 95.0000, 95.5000, 96.0000, 96.5000,\n",
       "        97.0000, 97.5000, 98.0000, 98.5000, 99.0000, 99.5000])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_to_somewhere=torch.arange(1,100,1/2)\n",
    "one_to_somewhere\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So basically we can also put fraction in step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensor datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#default is float32 for rand \n",
    "float_32_tensor=torch.arange(1,10,0.5)\n",
    "float_32_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_64_tensor=torch.tensor([1,2,3.5],dtype=int)\n",
    "int_64_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### some more params passed to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 4., 5.], device='cuda:0')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor=torch.tensor([3.0,4.0,5.0],\n",
    "                             dtype=None, # so that we don't have problem doing operation with float 16\n",
    "                             device=\"cuda\",  # be careful, tensor on cpu and gpu does not mix well\n",
    "                             requires_grad=False #no track gradient, idk what that means yet\n",
    "                             ,)\n",
    "float_32_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion of data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float16"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor=float_32_tensor.type(torch.float16)\n",
    "float_16_tensor.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### let see what happens if we multiply two different float with differnt bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 16., 25.], device='cuda:0')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor*float_32_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### let's multiply float and integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int16"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_16_tensor=float_16_tensor.type(torch.int16)\n",
    "int_16_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 16., 25.], device='cuda:0', dtype=torch.float16)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_16_tensor*float_16_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Python allows this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Errors I will get in tensor data \n",
    "-  ##### Tensor not right data type (find the data type , use tensor.dtype)\n",
    "-  ##### Tensor not right shape (get shape from tensor, use tensor.shape)\n",
    "-  ##### Tensor not right device (use tensor.device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### see this if you get the above errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4795, 0.3756, 0.1534, 0.3544, 0.5959],\n",
       "        [0.8278, 0.1998, 0.2545, 0.9696, 0.3852],\n",
       "        [0.4753, 0.6460, 0.5015, 0.0998, 0.0585]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debug_tensor=torch.rand(3,5)\n",
    "\n",
    "debug_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of tensor is torch.Size([3, 5])\n",
      "the datatypes of tensor is torch.float32\n",
      "the device of tensor is cpu\n"
     ]
    }
   ],
   "source": [
    "print(f'the shape of tensor is {debug_tensor.shape}')\n",
    "print(f'the datatypes of tensor is {debug_tensor.dtype}')\n",
    "print(f'the device of tensor is {debug_tensor.device}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manipulating Tensor (tensor operations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1: Addition (it must have same shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9589, 0.7512, 0.3068, 0.7088, 1.1918],\n",
       "        [1.6556, 0.3995, 0.5090, 1.9391, 0.7703],\n",
       "        [0.9506, 1.2919, 1.0030, 0.1997, 0.1171]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debug_tensor+debug_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10.4795, 10.3756, 10.1534, 10.3544, 10.5959],\n",
       "        [10.8278, 10.1998, 10.2545, 10.9696, 10.3852],\n",
       "        [10.4753, 10.6460, 10.5015, 10.0998, 10.0585]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debug_tensor +10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2: Subtraction (It must have same shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-9.5205, -9.6244, -9.8466, -9.6456, -9.4041],\n",
       "        [-9.1722, -9.8002, -9.7455, -9.0304, -9.6148],\n",
       "        [-9.5247, -9.3540, -9.4985, -9.9002, -9.9415]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debug_tensor -10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debug_tensor - debug_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3: Multiplication (two tensor must have cols and row same for first and second tensor in order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 5]), torch.Size([4, 5]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debug_tensor.shape, random_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (3) must match the size of tensor b (4) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m## this should not work\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mdebug_tensor\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrandom_tensor\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (3) must match the size of tensor b (4) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "## this should not work\n",
    "debug_tensor*random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 4])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transpose_random_tensor=np.transpose(random_tensor)\n",
    "transpose_random_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (5) must match the size of tensor b (4) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m## now we should be able to multiply debug tensor with transpose_random_tensor\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mdebug_tensor\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtranspose_random_tensor\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (5) must match the size of tensor b (4) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "## now we should be able to multiply debug tensor with transpose_random_tensor\n",
    "debug_tensor*transpose_random_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OH NO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 5]), torch.Size([5, 4]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debug_tensor.shape,transpose_random_tensor.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.4795, 0.3756, 0.1534, 0.3544, 0.5959],\n",
       "         [0.8278, 0.1998, 0.2545, 0.9696, 0.3852],\n",
       "         [0.4753, 0.6460, 0.5015, 0.0998, 0.0585]]),\n",
       " tensor([[0.9525, 0.2241, 0.8796, 0.0154],\n",
       "         [0.5990, 0.2574, 0.7477, 0.9468],\n",
       "         [0.5369, 0.0703, 0.2990, 0.6462],\n",
       "         [0.0340, 0.1525, 0.0600, 0.9703],\n",
       "         [0.7408, 0.0930, 0.1459, 0.4566]]))"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debug_tensor,transpose_random_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DAY-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let us now witness the time difference between matmul and the traditional way to multiply tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 2 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1.2175, 0.3244, 0.8567, 1.0780],\n",
       "        [1.3631, 0.4385, 1.0680, 1.4829],\n",
       "        [1.1557, 0.3287, 1.0656, 1.0666]])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "value1=torch.zeros(3,4)\n",
    "for x,i in enumerate(debug_tensor):\n",
    "    # print(i,x)\n",
    "    for cols in (range(transpose_random_tensor.shape[1])):\n",
    "\n",
    "        for y,j in enumerate(transpose_random_tensor):\n",
    "            \n",
    "                # print(i[y],j[cols])\n",
    "                value1[x][cols]+=i[y]*j[cols]\n",
    "                # print(x,cols)\n",
    "    \n",
    "value1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 3)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(len(debug_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1.2175, 0.3244, 0.8567, 1.0780],\n",
       "        [1.3631, 0.4385, 1.0680, 1.4829],\n",
       "        [1.1557, 0.3287, 1.0656, 1.0666]])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "value2=torch.matmul(debug_tensor,transpose_random_tensor)\n",
    "value2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True, False,  True,  True],\n",
       "        [ True,  True,  True,  True],\n",
       "        [ True,  True,  True,  True]])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value1==value2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CPU times: total: 0 ns ,Wall time: 2 ms vs CPU times: total: 0 ns, Wall time: 0 ns\n",
    "##### it is less than nano second which 10^(-9) that is more than million times faster than traditional method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Finding mean, max, mean and sum, etc, This might come in handy if i want to standarazie the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2.3733e-01, 2.1947e-01],\n",
       "         [6.3051e-01, 7.8455e-01],\n",
       "         [9.2240e-01, 5.8039e-02],\n",
       "         [4.1284e-01, 5.2453e-01],\n",
       "         [8.9033e-01, 8.1376e-01],\n",
       "         [5.1937e-01, 3.9539e-01],\n",
       "         [7.9916e-01, 4.5352e-01],\n",
       "         [1.9563e-01, 2.9965e-02],\n",
       "         [3.7313e-01, 1.4728e-01],\n",
       "         [3.4279e-01, 2.9387e-01],\n",
       "         [4.2301e-01, 9.7636e-01],\n",
       "         [7.4072e-01, 9.4776e-01],\n",
       "         [9.7924e-01, 8.6420e-01],\n",
       "         [4.5430e-01, 1.0378e-01],\n",
       "         [8.8538e-01, 3.7739e-01],\n",
       "         [5.3182e-01, 3.1639e-01],\n",
       "         [7.3721e-01, 2.5382e-01],\n",
       "         [6.9113e-01, 3.8304e-01],\n",
       "         [1.1124e-01, 4.4857e-02],\n",
       "         [3.3754e-01, 8.6627e-01],\n",
       "         [5.4232e-01, 2.5509e-02],\n",
       "         [8.5497e-01, 2.5127e-01],\n",
       "         [3.9120e-01, 8.6583e-01],\n",
       "         [3.7485e-01, 1.3583e-01],\n",
       "         [9.8844e-01, 5.9087e-02],\n",
       "         [6.9905e-01, 2.0960e-02],\n",
       "         [7.9757e-01, 4.9172e-01],\n",
       "         [2.4321e-01, 8.7089e-01],\n",
       "         [9.6044e-01, 8.8285e-01],\n",
       "         [5.8221e-01, 4.0715e-01],\n",
       "         [1.6026e-01, 7.7082e-01],\n",
       "         [4.6867e-01, 2.8329e-01],\n",
       "         [9.7753e-01, 6.6560e-01],\n",
       "         [4.2813e-01, 4.4514e-01],\n",
       "         [3.5996e-01, 7.8923e-01],\n",
       "         [7.8773e-02, 9.5249e-01],\n",
       "         [9.5563e-01, 5.2083e-01],\n",
       "         [5.4830e-01, 1.2619e-01],\n",
       "         [3.3350e-01, 7.1572e-02],\n",
       "         [2.4402e-01, 8.3878e-01],\n",
       "         [5.5734e-01, 2.8127e-01],\n",
       "         [2.7287e-01, 6.2416e-01],\n",
       "         [1.8382e-01, 2.7663e-01],\n",
       "         [3.8655e-01, 8.5847e-01],\n",
       "         [2.2567e-02, 5.2006e-01],\n",
       "         [1.6258e-02, 5.8813e-01],\n",
       "         [1.5158e-01, 4.3080e-01],\n",
       "         [2.0816e-01, 5.5328e-01],\n",
       "         [7.5731e-02, 6.2021e-01],\n",
       "         [9.9902e-01, 2.9238e-01],\n",
       "         [3.6598e-01, 6.9721e-01],\n",
       "         [3.6147e-01, 8.6274e-01],\n",
       "         [4.0765e-01, 4.6284e-01],\n",
       "         [2.5474e-01, 2.8873e-01],\n",
       "         [8.9723e-01, 3.9392e-01],\n",
       "         [8.2151e-01, 1.2970e-01],\n",
       "         [8.7321e-01, 4.8920e-01],\n",
       "         [3.8239e-02, 2.8900e-01],\n",
       "         [3.0634e-01, 1.4072e-01],\n",
       "         [2.0747e-01, 9.4472e-01],\n",
       "         [4.3658e-01, 8.0822e-01],\n",
       "         [8.3814e-01, 5.1500e-01],\n",
       "         [7.4584e-01, 6.2562e-01],\n",
       "         [7.1023e-01, 6.8049e-02],\n",
       "         [7.2516e-01, 9.6571e-02],\n",
       "         [2.5074e-01, 9.6329e-01],\n",
       "         [7.7185e-01, 3.6652e-01],\n",
       "         [2.6054e-01, 3.6814e-01],\n",
       "         [6.2012e-02, 8.9653e-01],\n",
       "         [4.4711e-01, 9.4671e-01],\n",
       "         [3.3062e-01, 2.7196e-01],\n",
       "         [7.7739e-01, 8.1220e-02],\n",
       "         [4.8870e-04, 3.9260e-01],\n",
       "         [3.2609e-01, 9.6292e-01],\n",
       "         [9.7675e-01, 4.7118e-01],\n",
       "         [6.2147e-01, 7.1409e-01],\n",
       "         [8.8813e-01, 9.7227e-01],\n",
       "         [2.5156e-01, 3.0062e-01],\n",
       "         [7.4671e-01, 8.7497e-01],\n",
       "         [5.0144e-01, 3.7489e-01],\n",
       "         [3.8101e-02, 5.3050e-01],\n",
       "         [4.4410e-01, 3.1288e-01],\n",
       "         [4.6125e-02, 9.9442e-01],\n",
       "         [6.9549e-01, 3.1415e-01],\n",
       "         [2.4518e-01, 4.9688e-01],\n",
       "         [5.4623e-01, 1.5437e-02],\n",
       "         [5.7909e-01, 6.9605e-01],\n",
       "         [5.3486e-01, 5.6975e-01],\n",
       "         [2.0747e-01, 9.6380e-01],\n",
       "         [4.8687e-01, 3.2974e-01],\n",
       "         [7.9342e-01, 6.5565e-01],\n",
       "         [8.5070e-01, 7.7891e-01],\n",
       "         [2.0211e-01, 8.7971e-01],\n",
       "         [4.7288e-01, 5.8711e-01],\n",
       "         [8.6539e-02, 1.3335e-01],\n",
       "         [9.6088e-01, 4.3580e-02],\n",
       "         [1.5189e-01, 4.6483e-01],\n",
       "         [8.7207e-02, 6.0081e-05],\n",
       "         [2.7960e-01, 4.8223e-03],\n",
       "         [7.3343e-01, 2.1285e-01]]])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.rand(1,100,2)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(96.8522), tensor(0.4843), tensor(6.0081e-05))"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(x), torch.mean(x),torch.min(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_int = torch.tensor([1,100],dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4843)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NOTE: this won't work because mean only takes float but we are providing int\n",
    "torch.mean(x_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(50.5000)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#After converting to float it should work\n",
    "torch.mean(x_int.type(torch.float))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding the position of the min, max?, use arg___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1), tensor(0))"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_int.argmax(),x_int.argmin()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping, Stacking, view\n",
    "- #### Reshaping - reshapes an input tensor to a defined shape,ok? \n",
    "- #### View - Return a view of an input tensor of a certain shape but keep the same memory as original tensor\n",
    "- #### Stacking - Combine multiple tensor on top of each other (vstack) or side by side (hstack)\n",
    "- #### Squeeze - removes all 1 dimensions from a tensor\n",
    "- #### Unsqueeze - adds 1 dimensions to a tensor\n",
    "- #### Permute - Return a view of the input with dimnesions permuted (swapped) in a certain way\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "         19, 20]),\n",
       " torch.Size([20]))"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(1,21)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2,  3,  4,  5],\n",
       "        [ 6,  7,  8,  9, 10],\n",
       "        [11, 12, 13, 14, 15],\n",
       "        [16, 17, 18, 19, 20]])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So basically the reshape x,y : x*y=tensor.shape\n",
    "x_reshaped=x.reshape(4,5)\n",
    "x_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 20]), torch.Size([20]))"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#View\n",
    "z=x.view(1,20) #extra dimension add ? z and x share same memory?\n",
    "z.shape,x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "z[:,0]=40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(40)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0] ## so changing z also makes changes to x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [20] at entry 0 and [4, 5] at entry 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[226], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Stack\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m x_stacked\u001b[38;5;241m=\u001b[39m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx_reshaped\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx_int\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m x_stacked\n",
      "\u001b[1;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [20] at entry 0 and [4, 5] at entry 1"
     ]
    }
   ],
   "source": [
    "# Stack\n",
    "x_stacked=torch.stack([x,x_reshaped,x_int])\n",
    "x_stacked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So every tensor needs to be of equal size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[40,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "          19, 20],\n",
       "         [40,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "          19, 20],\n",
       "         [40,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "          19, 20],\n",
       "         [40,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "          19, 20]]),\n",
       " torch.Size([4, 20]))"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_stacked=torch.stack([x,x,x,x],dim=0) #0 ma row wise stack hunxa 1 ma col wise i.e side by side\n",
    "x_stacked, x_stacked.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[40,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "          19, 20],\n",
       "         [40,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "          19, 20],\n",
       "         [40,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "          19, 20],\n",
       "         [40,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "          19, 20]]),\n",
       " torch.Size([4, 20]))"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# does not work because it does not have single dimension, unity dimension?\n",
    "x_stacked.squeeze()\n",
    "x_stacked,x_stacked.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), torch.Size([1, 10]))"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_x=torch.zeros(1,10)\n",
    "random_x,random_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before squeeze torch.Size([1, 10]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "after squeze torch.Size([1, 10]) tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f'before squeeze {random_x.shape}, {random_x}')\n",
    "x_squeeze=random_x.squeeze(dim=0)\n",
    "print(f'after squeze {x_squeeze.shape} {random_x}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
